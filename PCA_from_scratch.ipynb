{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of algorithms Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA_my:\n",
    "    \"\"\"\n",
    "    n_components - int, float or None. If int, then the first n_components component will be used. \n",
    "            If it is float, then components will be used such that the amount of variance \n",
    "            that needs to be explained is greater than the percentage specified by n_components. \n",
    "            If None, then all components will be used.\n",
    "            \n",
    "    Attributes:\n",
    "    principal_components_ - Principal axes in feature space, representing the directions of \n",
    "            maximum variance in the data. \n",
    "    eigenvalues_ - eigenvalues of the covariance matrix of X.\n",
    "    explain_variance_ratio_ - Percentage of variance explained by each of the selected components.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_components=None):\n",
    "        if type(n_components) in [int, float, type(None)]:\n",
    "            self.n_components = n_components\n",
    "        else:\n",
    "            raise ValueError('n_components. Wrong value')  \n",
    "        \n",
    "        self.principal_components_ = None\n",
    "        self.eigenvalues_ = None\n",
    "        self.explain_variance_ratio_ = None\n",
    "    \n",
    "    def __standardization(self, X: np.ndarray) -> np.ndarray:\n",
    "        mean = np.mean(X, axis=0)\n",
    "        return X - mean, mean  \n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Input\n",
    "            X - (n_samples, n_features) Training data, where n_samples is the number of samples and n_features \n",
    "            is the number of features.\n",
    "        Output\n",
    "            (n_samples, n_features) Transformed training data.\n",
    "        \"\"\"\n",
    "        X_adjust, mean = self.__standardization(X)\n",
    "        covariance_matrix = np.cov(X_adjust.T)\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)        \n",
    "        eigenvalues, eigenvectors = zip(*sorted(list(zip(eigenvalues,eigenvectors.T)), reverse=True))\n",
    "        eigenvalues, eigenvectors = np.array(eigenvalues), np.array(eigenvectors)\n",
    "        self.eigenvalues_ = eigenvalues\n",
    "        self.explain_variance_ratio_ = np.abs(eigenvalues/(np.sum(np.abs(eigenvalues))))        \n",
    "        \n",
    "        if self.n_components is None:\n",
    "            self.n_components = eigenvectors.shape[0]\n",
    "            \n",
    "        if type(self.n_components) is int:\n",
    "            self.principal_components_ = eigenvectors[:self.n_components]\n",
    "        elif type(self.n_components) is float:\n",
    "#             variance_significance = np.abs(eigenvalues/(np.sum(np.abs(eigenvalues))))\n",
    "            sum_ = 0\n",
    "            for idx, fraction in enumerate(self.explain_variance_ratio_):\n",
    "                sum_ += fraction\n",
    "                if sum_ >= self.n_components:\n",
    "                    self.principal_components_ = eigenvectors[:idx+1]\n",
    "                    break           \n",
    "\n",
    "        X_new = np.dot(self.principal_components_, X_adjust.T).T\n",
    "        \n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [2.5, 2.4],\n",
    "    [0.5, 0.7],\n",
    "    [2.2, 2.9],\n",
    "    [1.9, 2.2],\n",
    "    [3.1, 3.0],\n",
    "    [2.3, 2.7],\n",
    "    [2, 1.6],\n",
    "    [1, 1.1],\n",
    "    [1.5, 1.6],\n",
    "    [1.1, 0.9]   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_new:\n",
      " [[-0.82797019 -0.17511531]\n",
      " [ 1.77758033  0.14285723]\n",
      " [-0.99219749  0.38437499]\n",
      " [-0.27421042  0.13041721]\n",
      " [-1.67580142 -0.20949846]\n",
      " [-0.9129491   0.17528244]\n",
      " [ 0.09910944 -0.3498247 ]\n",
      " [ 1.14457216  0.04641726]\n",
      " [ 0.43804614  0.01776463]\n",
      " [ 1.22382056 -0.16267529]]\n",
      "Selected principal components:\n",
      " [[-0.6778734  -0.73517866]\n",
      " [-0.73517866  0.6778734 ]]\n",
      "Eigenvalues:\n",
      " [1.28402771 0.0490834 ]\n",
      "Percentage of variance explained:\n",
      " [0.96318131 0.03681869]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA_my(n_components=2)\n",
    "X_new = pca.fit(X)\n",
    "print(\"X_new:\\n\", X_new)\n",
    "print(\"Selected principal components:\\n\", pca.principal_components_)\n",
    "print(\"Eigenvalues:\\n\", pca.eigenvalues_)\n",
    "print(\"Percentage of variance explained:\\n\", pca.explain_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_sklearn = PCA(n_components=2)\n",
    "X_new_sklearn = pca_sklearn.fit_transform(X)\n",
    "pc_sklearn = pca_sklearn.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformation. Current implementation equals implementation from sklearn:  True\n",
      "Principal components. Current implementation equals implementation from sklearn:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"Data transformation. Current implementation equals implementation from sklearn: \", np.allclose(X_new, X_new_sklearn))\n",
    "print(\"Principal components. Current implementation equals implementation from sklearn: \", np.allclose(pca.principal_components_, pc_sklearn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "<ul>\n",
    "    <li><a href='https://builtin.com/data-science/step-step-explanation-principal-component-analysis'>https://builtin.com/data-science/step-step-explanation-principal-component-analysis</a></li>\n",
    "    <li><a href='http://www.cs.otago.ac.nz/cosc453/student_tutorials/principal_components.pdf'>http://www.cs.otago.ac.nz/cosc453/student_tutorials/principal_components.pdf</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
