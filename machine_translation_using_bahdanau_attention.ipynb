{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNGR0oLcNk+lWZWB/kWABaO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aakhterov/ML_algorithms_from_scratch/blob/master/machine_translation_using_bahdanau_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Description\n",
        "\n",
        "We're going to build an NN model to translate from Russian to English. This notebook is committed to the implementation of the simple encoder-decoder network with LSTM elements.\n",
        "\n",
        "We will use the following terms:\n",
        "- source language - the language from which the model translates\n",
        "- target language - the language to which the model translates\n",
        "- token = word\n",
        "\n",
        "\n",
        "Dataset: https://www.kaggle.com/datasets/hijest/englishrussian-dictionary-for-machine-translate/\n",
        "\n",
        "References:\n",
        "- https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/21_Machine_Translation.ipynb\n",
        "- https://www.youtube.com/watch?v=vI2Y3I-JI2Q\n",
        "- https://medium.com/analytics-vidhya/encoder-decoder-seq2seq-models-clearly-explained-c34186fbf49b\n",
        "\n"
      ],
      "metadata": {
        "id": "m-9HBe6We5LC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrOij2Lsj3yA",
        "outputId": "5aa03194-370b-4291-de64-4c3e91f01313"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from typing import List\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from string import punctuation\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "base_path = '/content/drive/MyDrive/Colab Notebooks/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Vectorization"
      ],
      "metadata": {
        "id": "2IEg-hGLJfDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UNKNOWN_TOKEN = '[UNK]' # Out of vocabulary token\n",
        "START_TOKEN = '[START]' # The token that denotes the beginning of the target language phrase\n",
        "END_TOKEN = '[END]' # The token that denotes the end of the target language phrase"
      ],
      "metadata": {
        "id": "_RSzJxTxSmLY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Vectorization:\n",
        "  '''\n",
        "    Vectorization text class.\n",
        "    Main goals:\n",
        "     - make a vocabulary\n",
        "     - convert the list of strings to the list of integer tokens\n",
        "     - convert the list of integer tokens to the list of strings\n",
        "  '''\n",
        "\n",
        "  def __init__(self,\n",
        "               max_tokens,\n",
        "               max_length=None,\n",
        "               unknown_token=UNKNOWN_TOKEN,\n",
        "               start_token=START_TOKEN,\n",
        "               end_token=END_TOKEN\n",
        "               ):\n",
        "    '''\n",
        "      :param max_tokens: length of the vocabulary\n",
        "      :param max_length: max length of the phrases\n",
        "      :param unknown_token: out of vocabulary token\n",
        "      :param start_token: token that denotes the beginning of the phrase\n",
        "      :param end_token: token that denotes the end of the phrase\n",
        "    '''\n",
        "    self.max_tokens = max_tokens\n",
        "    self.max_length = max_length\n",
        "    self.unknown_token = unknown_token\n",
        "    self.start_token = start_token\n",
        "    self.end_token=end_token\n",
        "    # add to the vocabulary:\n",
        "    #  (1) padding token (we're going to pad using 0, so padding token index is 0)\n",
        "    #  (2) out of vocabulary token\n",
        "    #  (3) start token\n",
        "    #  (4) end token\n",
        "    self.vocabulary = ['', self.unknown_token, self.start_token, self.end_token]\n",
        "\n",
        "  def __preprocessing(self, input: str) -> str:\n",
        "    '''\n",
        "      Preprocess of the string (convert to lowcase and remove punctuation).\n",
        "      ex.: I'm going! -> i m going\n",
        "      :param input - input string\n",
        "      :return preprocessed string\n",
        "    '''\n",
        "    output = ''.join(map(lambda ch: ch if ch not in punctuation else ' ', input.lower())).strip()\n",
        "    return output\n",
        "\n",
        "  def token_to_text(self, tokens: List) -> str:\n",
        "    '''\n",
        "      Convert the list of the integer tokens to the string\n",
        "      :param tokens: list of the integer tokens\n",
        "      :return string contains words that correspond to the integer tokens\n",
        "    '''\n",
        "    words = [self.vocabulary[token] for token in tokens]\n",
        "    return \" \".join(words)\n",
        "\n",
        "  def fit(self, X: List):\n",
        "    '''\n",
        "      Make the vocabulary and calculate the max length of the phrase\n",
        "      :param X: corpus - list of the strings\n",
        "      :return the instance of the current class\n",
        "    '''\n",
        "    lens = []\n",
        "    for x in X:\n",
        "      # Make preprocessing and get the list of the words.\n",
        "      # Ex. I'm going! -> ['i', 'm', 'going']\n",
        "      words = self.__preprocessing(x).split()\n",
        "\n",
        "      # Collect phrases lengths\n",
        "      lens.append(len(words))\n",
        "\n",
        "      # Make the vocabulary\n",
        "      for word in words:\n",
        "        token = word.strip()\n",
        "        # Add the word to the vocabulary if it usn't \"full\"\n",
        "        if token not in self.vocabulary and self.max_tokens is not None and len(self.vocabulary)<self.max_tokens:\n",
        "          self.vocabulary.append(token)\n",
        "\n",
        "    # Calculate the max length of the phrases if it isn't set in the __init__\n",
        "    # max_length = Average length + two standard devations\n",
        "    lens = np.array(lens)\n",
        "    if self.max_length is None:\n",
        "      self.max_length = int(np.mean(lens) + 2 * np.std(lens))\n",
        "    return self\n",
        "\n",
        "  def predict(self,\n",
        "              X: List[str],\n",
        "              is_padding=True,\n",
        "              is_add_start_token=False,\n",
        "              is_add_end_token=False\n",
        "              ) -> List[List]:\n",
        "    '''\n",
        "      :param X - corpus - list of the strings\n",
        "      :param is_padding - whether to pad the list of tokens to the max. length with 0s\n",
        "      :param is_add_start_token - whether to add the start_token to the list of tokens\n",
        "      :param is_add_end_token - whether to add the end_token to the list of tokens\n",
        "      :return list of the lists of tokens\n",
        "    '''\n",
        "    output = []\n",
        "    self.max_length += int(is_add_start_token) + int(is_add_end_token)\n",
        "\n",
        "    for x in X:\n",
        "      # If nedded add the index of the start_token to the beginning of the list of tokens\n",
        "      vector = [self.vocabulary.index(self.start_token)] if is_add_start_token else []\n",
        "\n",
        "      # Make preprocessing and get the list of the words.\n",
        "      words = self.__preprocessing(x).split()\n",
        "\n",
        "      # If the current word is in the vocabulary add its index to the list else add the index of the unknown_token\n",
        "      for word in words:\n",
        "        token = word.strip()\n",
        "        vector.append(self.vocabulary.index(token) if token in self.vocabulary else self.vocabulary.index(self.unknown_token))\n",
        "\n",
        "      # Truncate the vector to the max. length\n",
        "      vector = vector[:self.max_length-1]\n",
        "\n",
        "      # If needed add the index of the end_token\n",
        "      if is_add_end_token:\n",
        "        vector.append(self.vocabulary.index(self.end_token))\n",
        "\n",
        "      output.append(vector)\n",
        "\n",
        "    # If needed pad the vector to the max. length with 0s\n",
        "    return pad_sequences(output,\n",
        "                         maxlen=self.max_length,\n",
        "                         padding='post',\n",
        "                         truncating='post') if is_padding else output"
      ],
      "metadata": {
        "id": "OwlrS_c8K6pU"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the first M samples\n",
        "M = 1_000\n",
        "\n",
        "input_phrases, output_phrases = [], []\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/Data/rus.txt') as f:\n",
        "  for line in f.readlines()[:M]:\n",
        "    x, y = line.split('CC-BY')[0].strip().split('\\t')\n",
        "    input_phrases.append(x)\n",
        "    output_phrases.append(y)"
      ],
      "metadata": {
        "id": "VvaCDzcFuIe1"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_vocab = 10_000 # size of the source language vocaulary\n",
        "output_vocab = 10_000 # size of the target language vocaulary"
      ],
      "metadata": {
        "id": "d-LhZGvyvrkS"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make vectorization of the source language phrases\n",
        "encoder_vec = Vectorization(max_tokens=input_vocab)\n",
        "encoder_vec.fit(input_phrases)\n",
        "X_encoder = encoder_vec.predict(input_phrases)\n",
        "\n",
        "# Make vectorization of the target language phrases\n",
        "decoder_vec = Vectorization(max_tokens=output_vocab)\n",
        "decoder_vec.fit(output_phrases)\n",
        "# For the reason of the sequence model training we need decoder input contains the start_token and\n",
        "# the decoder output which is without the start_token\n",
        "X_decoder = decoder_vec.predict(output_phrases, is_add_start_token=True, is_add_end_token=True)\n",
        "Y_decoder = decoder_vec.predict(output_phrases, is_add_end_token=True)"
      ],
      "metadata": {
        "id": "chd-W_mXVgqE"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 1\n",
        "print(f\"Index: {idx}\")\n",
        "print(\"======= Encoder =======\")\n",
        "print(f\"Input phrase: {input_phrases[idx]}\")\n",
        "print(f\"Vector: {X_encoder[idx]}\")\n",
        "print(f\"Max. length: {encoder_vec.max_length}\")\n",
        "print(\"======= Decoder =======\")\n",
        "print(f\"Input phrase: {output_phrases[idx]}\")\n",
        "print(f\"Vector: {X_decoder[idx]}\")\n",
        "print(f\"Output phrase: {output_phrases[idx]}\")\n",
        "print(f\"Vector: {Y_decoder[idx]}\")\n",
        "print(f\"Max. length: {decoder_vec.max_length}\")\n",
        "print(\"==============\")\n",
        "print(f\"Start phrase token index: {decoder_vec.vocabulary.index(START_TOKEN)}\")\n",
        "print(f\"End phrase token index: {decoder_vec.vocabulary.index(END_TOKEN)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHSeTSRGQhmS",
        "outputId": "eaa3c13f-70ff-45d6-82b1-60a7fe5bc1e8"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: 1\n",
            "======= Encoder =======\n",
            "Input phrase: Go.\n",
            "Vector: [4 0 0]\n",
            "Max. length: 3\n",
            "======= Decoder =======\n",
            "Input phrase: Иди.\n",
            "Vector: [2 5 3 0 0]\n",
            "Output phrase: Иди.\n",
            "Vector: [5 3 0 0 0 0]\n",
            "Max. length: 6\n",
            "==============\n",
            "Start phrase token index: 2\n",
            "End phrase token index: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Construct encoder-decoder NNs"
      ],
      "metadata": {
        "id": "77Qm_uDxJonO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 64\n",
        "lstm_hidden_units = 64"
      ],
      "metadata": {
        "id": "R7HQ2-Sqlpye"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, input_vocab, embedding_dim, lstm_hidden_units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.lstm_hidden_units = lstm_hidden_units\n",
        "    self.emedding = Embedding(input_dim=input_vocab,\n",
        "                              output_dim=embedding_dim,\n",
        "                              mask_zero=True,\n",
        "                              name='encoder_embedding')\n",
        "    self.lstm = LSTM(units=lstm_hidden_units,\n",
        "                    #  return_sequences=True,\n",
        "                     return_state=True,\n",
        "                     name='encoder_lstm')\n",
        "\n",
        "  def __call__(self, x):\n",
        "    out = self.emedding(x)\n",
        "    _, h, c = self.lstm(out)\n",
        "    return h, c"
      ],
      "metadata": {
        "id": "vPXQD5tFjzwp"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, units: int, name=None):\n",
        "    super(BahdanauAttention, self).__init__(name=name)\n",
        "    self.units = units\n",
        "    self.fc_encoder_states = Dense(units=units, activation='linear')\n",
        "    self.fc_decoder_states = Dense(units=units, activation='linear')\n",
        "    self.fc_combined = Dense(units=1, activation='linear')\n",
        "\n",
        "  def __call__(self, encoder_states, decoder_hidden_state):\n",
        "    fc_encoder_out = self.fc_encoder_states(encoder_states)\n",
        "    # print(f\"fc_encoder_out.shape={fc_encoder_out.shape}\")\n",
        "    fc_decoder_out = self.fc_decoder_states(decoder_hidden_state)\n",
        "    # print(f\"fc_decoder_out.shape={fc_decoder_out.shape}\")\n",
        "    fc_decoder_out = tf.expand_dims(fc_decoder_out, axis=1)\n",
        "    # print(f\"Expanded fc_decoder_out.shape={fc_decoder_out.shape}\")\n",
        "    alignment_scores = self.fc_combined(tf.math.tanh(fc_encoder_out + fc_decoder_out))\n",
        "    # print(f\"alignment_scores.shape={alignment_scores.shape}\")\n",
        "    softmax_alignment_scores = tf.nn.softmax(alignment_scores)\n",
        "    context_vector = tf.reduce_sum(softmax_alignment_scores * encoder_states, axis=1)\n",
        "    # print(f\"context_vector.shape={context_vector.shape}\")\n",
        "    return context_vector, softmax_alignment_scores"
      ],
      "metadata": {
        "id": "B4DhtzjnPE_5"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, output_vocab, embedding_dim, lstm_hidden_units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.emedding = Embedding(input_dim=output_vocab,\n",
        "                              output_dim=embedding_dim,\n",
        "                              mask_zero=True,\n",
        "                              name='decoder_embedding')\n",
        "\n",
        "    self.lstm = LSTM(units=lstm_hidden_units,\n",
        "                     return_sequences=True,\n",
        "                     return_state=True,\n",
        "                     name='decoder_lstm')\n",
        "\n",
        "    self.attention = BahdanauAttention(units=lstm_hidden_units,\n",
        "                                       name='decoder_attention')\n",
        "\n",
        "    # Dense layer with softmax activation function\n",
        "    self.output_dense = Dense(units=output_vocab,\n",
        "                              activation='softmax',\n",
        "                              name='decoder_output')\n",
        "\n",
        "  def __call__(self, x, decoder_states, encoder_states):\n",
        "    hidden_state, cell_state = decoder_states\n",
        "    context_vector, _ = self.attention(encoder_states, hidden_state)\n",
        "    # print(context_vector.shape)\n",
        "    out = self.emedding(x)\n",
        "    # print(out.shape)\n",
        "    input = tf.concat([tf.expand_dims(context_vector, axis=1), out], axis=-1)\n",
        "    out, h, c = self.lstm(input, initial_state=decoder_states)\n",
        "    # print(out.shape)\n",
        "    # print(h.shape)\n",
        "    out = self.output_dense(out)\n",
        "    return out, h, c"
      ],
      "metadata": {
        "id": "tL1KwedDnTc3"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqBahdanauAttention(tf.keras.Model):\n",
        "\n",
        "  def __init__(self,\n",
        "               input_vocab,\n",
        "               output_vocab,\n",
        "               encoder_embd_dim,\n",
        "               decoder_embd_dim,\n",
        "               encoder_lstm_units,\n",
        "               decoder_lstm_units,\n",
        "               max_output_length,\n",
        "               start_token_index,\n",
        "               end_token_index):\n",
        "\n",
        "    super(Seq2SeqBahdanauAttention, self).__init__()\n",
        "    self.encoder = Encoder(input_vocab=input_vocab,\n",
        "                           embedding_dim=encoder_embd_dim,\n",
        "                           lstm_hidden_units=encoder_lstm_units)\n",
        "    self.decoder = Decoder(output_vocab=output_vocab,\n",
        "                           embedding_dim=decoder_embd_dim,\n",
        "                           lstm_hidden_units=decoder_lstm_units)\n",
        "    self.max_output_length = max_output_length\n",
        "    self.start_token_index = start_token_index\n",
        "    self.end_token_index = end_token_index\n",
        "\n",
        "  def __forward(self, X_encoder, X_decoder=None, Y_decoder=None):\n",
        "    output = []\n",
        "    batch_size = X_encoder.shape[0]\n",
        "    # sequence_length = X_encoder.shape[1]\n",
        "    encoder_states = []\n",
        "    loss = 0\n",
        "    for t in range(X_encoder.shape[1]):\n",
        "      h, c = self.encoder(X_encoder[:, :t+1])\n",
        "      encoder_states.append(h)\n",
        "    encoder_states = tf.stack(encoder_states, axis=1)\n",
        "    hidden_state = encoder_states[:, -1, :]\n",
        "    cell_state = c\n",
        "\n",
        "    if X_decoder is not None and Y_decoder is not None:\n",
        "      decoder_input = X_decoder[:, :1]\n",
        "      for t in range(X_decoder.shape[1]):\n",
        "        out, hidden_state, cell_state = self.decoder(x=decoder_input,\n",
        "                                                     decoder_states=(hidden_state, cell_state),\n",
        "                                                     encoder_states=encoder_states)\n",
        "        output.append(out)\n",
        "        loss += tf.keras.losses.sparse_categorical_crossentropy(Y_decoder[:, t], out)\n",
        "    else:\n",
        "        current_step = 0\n",
        "        token = self.start_token_index\n",
        "        while current_step<self.max_output_length and token!=self.end_token_index:\n",
        "          decoder_input = np.array([[token]])\n",
        "          out, hidden_state, cell_state = self.decoder(x=decoder_input,\n",
        "                                                      decoder_states=(hidden_state, cell_state),\n",
        "                                                      encoder_states=encoder_states)\n",
        "          if Y_decoder is not None:\n",
        "            loss += tf.keras.losses.sparse_categorical_crossentropy(Y_decoder[:, current_step], out)\n",
        "\n",
        "          token = np.argmax(out)\n",
        "          output.append(token)\n",
        "          current_step += 1\n",
        "\n",
        "    batch_loss = tf.reduce_sum(loss) / Y_decoder.shape[0] if Y_decoder is not None else None\n",
        "    return output, loss, batch_loss\n",
        "\n",
        "  def __train_step(self, X_encoder, X_decoder, Y_decoder):\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    with tf.GradientTape() as tape:\n",
        "      _, loss, batch_loss = self.__forward(X_encoder, X_decoder, Y_decoder)\n",
        "      variables = self.encoder.trainable_variables + self.decoder.trainable_variables\n",
        "      gradients = tape.gradient(loss, variables)\n",
        "      optimizer.apply_gradients(zip(gradients, variables))\n",
        "    return batch_loss\n",
        "\n",
        "  def fit(self, X_encoder, X_decoder, Y_decoder, epoch=20, batch_size=64, train_size=0.8):\n",
        "    M = X_encoder.shape[0]\n",
        "    train_sample_size = int(train_size*M)\n",
        "    full_dataset = tf.data.Dataset.from_tensor_slices((X_encoder, X_decoder, Y_decoder)).shuffle(M)\n",
        "    train_ds = full_dataset.take(train_sample_size).batch(batch_size)\n",
        "    test_ds = full_dataset.skip(train_sample_size)\n",
        "\n",
        "    total_train_batches = train_ds.cardinality()\n",
        "    test_ds_size = test_ds.cardinality()\n",
        "\n",
        "    history = {\"train_loss\": [], \"test_loss\": []}\n",
        "\n",
        "    for ep in range(1, epoch+1):\n",
        "      print(f\"Epoch {ep}/{epoch}\")\n",
        "      total_loss = 0\n",
        "      for batch, (X_batch_encoder,\n",
        "                  X_batch_decoder,\n",
        "                  Y_batch_decoder) in tqdm(enumerate(train_ds.take(total_train_batches)),\n",
        "                                           desc=f\"Train dataset ({total_train_batches} batches. Total {batch_size*total_train_batches} samples)\"):\n",
        "        batch_loss = self.__train_step(X_batch_encoder, X_batch_decoder, Y_batch_decoder)\n",
        "        total_loss += batch_loss\n",
        "\n",
        "      history[\"train_loss\"].append(total_loss)\n",
        "      print(f\"Loss on train: {total_loss}\")\n",
        "\n",
        "      total_loss = 0\n",
        "      for X_test_encoder, X_test_decoder, Y_test_decoder in tqdm(test_ds,\n",
        "                                                                 desc=f\"Test dataset ({test_ds_size} samples)\"):\n",
        "        _, _, batch_loss = self.__forward(tf.expand_dims(X_test_encoder, 0),\n",
        "                                          None,\n",
        "                                          tf.expand_dims(Y_test_decoder, 0))\n",
        "        total_loss += batch_loss\n",
        "\n",
        "      history[\"test_loss\"].append(total_loss)\n",
        "      print(f\"Loss on test: {total_loss}\")\n",
        "    return history\n",
        "\n",
        "  def predict(self, X_encoder):\n",
        "    out, _, _ = self.__forward(X_encoder)\n",
        "    return out"
      ],
      "metadata": {
        "id": "caH2BctcgtQ_"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Seq2SeqBahdanauAttention(input_vocab=input_vocab,\n",
        "                                 output_vocab=output_vocab,\n",
        "                                 encoder_embd_dim=embedding_dim,\n",
        "                                 decoder_embd_dim=embedding_dim,\n",
        "                                 encoder_lstm_units=lstm_hidden_units,\n",
        "                                 decoder_lstm_units=lstm_hidden_units,\n",
        "                                 max_output_length=decoder_vec.max_length,\n",
        "                                 start_token_index=decoder_vec.vocabulary.index(START_TOKEN),\n",
        "                                 end_token_index=decoder_vec.vocabulary.index(END_TOKEN))"
      ],
      "metadata": {
        "id": "Jn12K0-qgtY0"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_encoder, X_decoder, Y_decoder, epoch=20, batch_size=64, train_size=0.8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "RCJ4QCjxGVnB",
        "outputId": "b42abab2-c52f-4a41-d989-9fc53ad0ac77"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset (13 batches. Total 832 samples): 13it [00:06,  1.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 596.3899536132812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset (200 samples):  50%|████▉     | 99/200 [00:14<00:13,  7.57it/s]Exception ignored in: <generator object tqdm.__iter__ at 0x7e9010f0cb30>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1183, in __iter__\n",
            "    yield obj\n",
            "KeyboardInterrupt: \n",
            "Test dataset (200 samples):  50%|████▉     | 99/200 [00:20<00:20,  4.84it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-185-38fdb826a5f0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-183-c49a1453ae00>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_encoder, X_decoder, Y_decoder, epoch, batch_size, train_size)\u001b[0m\n\u001b[1;32m     95\u001b[0m       for X_test_encoder, X_test_decoder, Y_test_decoder in tqdm(test_ds,\n\u001b[1;32m     96\u001b[0m                                                                  desc=f\"Test dataset ({test_ds_size} samples)\"):  \n\u001b[0;32m---> 97\u001b[0;31m         _, _, batch_loss = self.__forward(tf.expand_dims(X_test_encoder, 0), \n\u001b[0m\u001b[1;32m     98\u001b[0m                                           \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                                           tf.expand_dims(Y_test_decoder, 0))  \n",
            "\u001b[0;32m<ipython-input-183-c49a1453ae00>\u001b[0m in \u001b[0;36m__forward\u001b[0;34m(self, X_encoder, X_decoder, Y_decoder)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m       \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_encoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m       \u001b[0mencoder_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mencoder_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-6758e68ee68a>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/base_rnn.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m                 \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_autographed_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1128\u001b[0;31m             call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[0m\u001b[1;32m   1129\u001b[0m                 \u001b[0mcall_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m                 object_name=(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36minject_argument_info_in_traceback\u001b[0;34m(fn, object_name)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/tf_decorator.py\u001b[0m in \u001b[0;36mmake_decorator\u001b[0;34m(target, decorator_func, decorator_name, decorator_doc, decorator_argspec)\u001b[0m\n\u001b[1;32m    136\u001b[0m   decorator = TFDecorator(decorator_name, target, decorator_doc,\n\u001b[1;32m    137\u001b[0m                           decorator_argspec)\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecorator_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_tf_decorator'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m   \u001b[0;31m# Objects that are callables (e.g., a functools.partial object) may not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;31m# the following attributes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cxMVzNhUeGi-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}