{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aakhterov/ML_algorithms_from_scratch/blob/master/machine_translation_using_bahdanau_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-9HBe6We5LC"
      },
      "source": [
        "# 0. Description\n",
        "\n",
        "We're going to build an NN model to translate from Russian to English. This notebook is committed to the implementation of the encoder-decoder network with Bahdanau attention (Additive Attention) mechanism.\n",
        "\n",
        "We will use the following terms:\n",
        "- source language - the language from which the model translates\n",
        "- target language - the language to which the model translates\n",
        "- token = word\n",
        "\n",
        "\n",
        "Dataset: https://www.kaggle.com/datasets/hijest/englishrussian-dictionary-for-machine-translate/\n",
        "\n",
        "References:\n",
        "- https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/21_Machine_Translation.ipynb\n",
        "- https://www.youtube.com/watch?v=vI2Y3I-JI2Q\n",
        "- https://medium.com/analytics-vidhya/encoder-decoder-seq2seq-models-clearly-explained-c34186fbf49b\n",
        "- https://blog.floydhub.com/attention-mechanism/#bahdanau-att-step2\n",
        "- https://towardsdatascience.com/implementing-neural-machine-translation-with-attention-using-tensorflow-fc9c6f26155f\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrOij2Lsj3yA",
        "outputId": "73301320-384f-431e-b481-c9582847f374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from typing import List\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "base_path = '/content/drive/MyDrive/Colab Notebooks/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IEg-hGLJfDv"
      },
      "source": [
        "# 1. Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_RSzJxTxSmLY"
      },
      "outputs": [],
      "source": [
        "UNKNOWN_TOKEN = '[UNK]' # Out of vocabulary token\n",
        "START_TOKEN = '[START]' # The token that denotes the beginning of the target language phrase\n",
        "END_TOKEN = '[END]' # The token that denotes the end of the target language phrase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "id": "OwlrS_c8K6pU"
      },
      "outputs": [],
      "source": [
        "class Vectorization:\n",
        "  '''\n",
        "    Vectorization text class.\n",
        "    Main goals:\n",
        "     - make a vocabulary\n",
        "     - convert the list of strings to the list of integer tokens\n",
        "     - convert the list of integer tokens to the list of strings\n",
        "  '''\n",
        "\n",
        "  def __init__(self,\n",
        "               max_tokens,\n",
        "               max_length=None,\n",
        "               unknown_token=UNKNOWN_TOKEN,\n",
        "               start_token=START_TOKEN,\n",
        "               end_token=END_TOKEN\n",
        "               ):\n",
        "    '''\n",
        "      :param max_tokens: length of the vocabulary\n",
        "      :param max_length: max length of the phrases\n",
        "      :param unknown_token: out of vocabulary token\n",
        "      :param start_token: token that denotes the beginning of the phrase\n",
        "      :param end_token: token that denotes the end of the phrase\n",
        "    '''\n",
        "    self.max_tokens = max_tokens\n",
        "    self.max_length = max_length\n",
        "    self.unknown_token = unknown_token\n",
        "    self.start_token = start_token\n",
        "    self.end_token=end_token\n",
        "    # add to the vocabulary:\n",
        "    #  (1) padding token (we're going to pad using 0, so padding token index is 0)\n",
        "    #  (2) out of vocabulary token\n",
        "    #  (3) start token\n",
        "    #  (4) end token\n",
        "    self.vocabulary = ['', self.unknown_token, self.start_token, self.end_token]\n",
        "\n",
        "  def __preprocessing(self, input: str) -> str:\n",
        "    '''\n",
        "      Preprocess of the string (convert to lowcase and remove punctuation).\n",
        "      ex.: I'm going! -> i m going\n",
        "      :param input - input string\n",
        "      :return preprocessed string\n",
        "    '''\n",
        "    output = ''.join(map(lambda ch: ch if ch not in punctuation else ' ', input.lower())).strip()\n",
        "    return output\n",
        "\n",
        "  def token_to_text(self, tokens: List) -> str:\n",
        "    '''\n",
        "      Convert the list of the integer tokens to the string\n",
        "      :param tokens: list of the integer tokens\n",
        "      :return string contains words that correspond to the integer tokens\n",
        "    '''\n",
        "    words = [self.vocabulary[token] if token in self.vocabulary else self.unknown_token for token in tokens]\n",
        "    return \" \".join(words)\n",
        "\n",
        "  def fit(self, X: List, is_add_start_token=False, is_add_end_token=False):\n",
        "    '''\n",
        "      Make the vocabulary and calculate the max length of the phrase\n",
        "      :param X: corpus - list of the strings\n",
        "      :return the instance of the current class\n",
        "    '''\n",
        "    lens = []\n",
        "    __vocab = []\n",
        "    for x in X:\n",
        "      # Make preprocessing and get the list of the words.\n",
        "      # Ex. I'm going! -> ['i', 'm', 'going']\n",
        "      words = self.__preprocessing(x).split()\n",
        "\n",
        "      # Collect phrases lengths\n",
        "      lens.append(len(words))\n",
        "\n",
        "      # Make the vocabulary\n",
        "      __vocab += [word.strip() for word in words]\n",
        "\n",
        "      # for word in words:\n",
        "      #   token = word.strip()\n",
        "      #   # Add the word to the vocabulary if it usn't \"full\"\n",
        "      #   if token not in self.vocabulary and self.max_tokens is not None and len(self.vocabulary)<self.max_tokens:\n",
        "      #     self.vocabulary.append(token)\n",
        "\n",
        "    c = Counter(__vocab)\n",
        "    if self.max_tokens:\n",
        "      self.vocabulary += [item[0] for item in c.most_common(self.max_tokens-4)]\n",
        "    else:\n",
        "      self.vocabulary += [item[0] for item in c.most_common()]\n",
        "\n",
        "    # Calculate the max length of the phrases if it isn't set in the __init__\n",
        "    # max_length = Average length + two standard devations\n",
        "    lens = np.array(lens)\n",
        "    if self.max_length is None:\n",
        "      self.max_length = int(np.mean(lens) + 2 * np.std(lens)) + int(is_add_start_token) + int(is_add_end_token)\n",
        "    return self\n",
        "\n",
        "  def predict(self,\n",
        "              X: List[str],\n",
        "              is_padding=True,\n",
        "              is_add_start_token=False,\n",
        "              is_add_end_token=False\n",
        "              ) -> List[List]:\n",
        "    '''\n",
        "      :param X - corpus - list of the strings\n",
        "      :param is_padding - whether to pad the list of tokens to the max. length with 0s\n",
        "      :param is_add_start_token - whether to add the start_token to the list of tokens\n",
        "      :param is_add_end_token - whether to add the end_token to the list of tokens\n",
        "      :return list of the lists of tokens\n",
        "    '''\n",
        "    output = []\n",
        "    # max_length = self.max_length + int(is_add_start_token) + int(is_add_end_token)\n",
        "\n",
        "    for x in X:\n",
        "      # If nedded add the index of the start_token to the beginning of the list of tokens\n",
        "      vector = [self.vocabulary.index(self.start_token)] if is_add_start_token else []\n",
        "\n",
        "      # Make preprocessing and get the list of the words.\n",
        "      words = self.__preprocessing(x).split()\n",
        "\n",
        "      # If the current word is in the vocabulary add its index to the list else add the index of the unknown_token\n",
        "      for word in words:\n",
        "        token = word.strip()\n",
        "        vector.append(self.vocabulary.index(token) if token in self.vocabulary else self.vocabulary.index(self.unknown_token))\n",
        "\n",
        "      # Truncate the vector to the max. length\n",
        "      vector = vector[:self.max_length-1]\n",
        "\n",
        "      # If needed add the index of the end_token\n",
        "      if is_add_end_token:\n",
        "        vector.append(self.vocabulary.index(self.end_token))\n",
        "\n",
        "      output.append(vector)\n",
        "\n",
        "    # If needed pad the vector to the max. length with 0s\n",
        "    return pad_sequences(output,\n",
        "                         maxlen=self.max_length,\n",
        "                         padding='post',\n",
        "                         truncating='post') if is_padding else output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "id": "VvaCDzcFuIe1"
      },
      "outputs": [],
      "source": [
        "# Read from N to M samples\n",
        "N = 100_000\n",
        "M = 110_000\n",
        "\n",
        "input_phrases, output_phrases = [], []\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/Data/rus.txt') as f:\n",
        "  for line in f.readlines()[N:M]:\n",
        "    eng, rus = line.split('CC-BY')[0].strip().split('\\t')\n",
        "    input_phrases.append(rus)\n",
        "    output_phrases.append(eng)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "id": "d-LhZGvyvrkS"
      },
      "outputs": [],
      "source": [
        "input_vocab = 2000 # size of the source language vocaulary\n",
        "output_vocab = 2000 # size of the target language vocaulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "id": "chd-W_mXVgqE"
      },
      "outputs": [],
      "source": [
        "# Make vectorization of the source language phrases\n",
        "encoder_vec = Vectorization(max_tokens=input_vocab)\n",
        "encoder_vec.fit(input_phrases)\n",
        "X_encoder = encoder_vec.predict(input_phrases, is_padding=False)\n",
        "\n",
        "# Make vectorization of the target language phrases\n",
        "decoder_vec = Vectorization(max_tokens=output_vocab)\n",
        "decoder_vec.fit(output_phrases, is_add_start_token=True, is_add_end_token=True)\n",
        "# For the reason of the sequence model training we need decoder input contains the start_token and\n",
        "# the decoder output which is without the start_token\n",
        "X_decoder = decoder_vec.predict(output_phrases, is_add_start_token=True, is_add_end_token=True)\n",
        "Y_decoder = decoder_vec.predict(output_phrases, is_add_end_token=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHSeTSRGQhmS",
        "outputId": "7b4ac067-7ccb-42fe-bbc5-b27a694e8109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: 100\n",
            "======= Encoder =======\n",
            "Input phrase: Том знает, кто я?\n",
            "Vector: [5, 69, 97, 4]\n",
            "Max. length: 6\n",
            "======= Decoder =======\n",
            "Input phrase: Does Tom know who I am?\n",
            "Vector: [  2 115   5  30 203   4 135   3]\n",
            "Output phrase: Does Tom know who I am?\n",
            "Vector: [115   5  30 203   4 135   3   0]\n",
            "Max. length: 8\n",
            "==============\n",
            "Start phrase token index: 2\n",
            "End phrase token index: 3\n"
          ]
        }
      ],
      "source": [
        "idx = 100\n",
        "print(f\"Index: {idx}\")\n",
        "print(\"======= Encoder =======\")\n",
        "print(f\"Input phrase: {input_phrases[idx]}\")\n",
        "print(f\"Vector: {X_encoder[idx]}\")\n",
        "print(f\"Max. length: {encoder_vec.max_length}\")\n",
        "print(\"======= Decoder =======\")\n",
        "print(f\"Input phrase: {output_phrases[idx]}\")\n",
        "print(f\"Vector: {X_decoder[idx]}\")\n",
        "print(f\"Output phrase: {output_phrases[idx]}\")\n",
        "print(f\"Vector: {Y_decoder[idx]}\")\n",
        "print(f\"Max. length: {decoder_vec.max_length}\")\n",
        "print(\"==============\")\n",
        "print(f\"Start phrase token index: {decoder_vec.vocabulary.index(START_TOKEN)}\")\n",
        "print(f\"End phrase token index: {decoder_vec.vocabulary.index(END_TOKEN)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77Qm_uDxJonO"
      },
      "source": [
        "# 2. Construct Encoder-Decoder NN with Bahdanau attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "vPXQD5tFjzwp"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  '''\n",
        "    Encoder for using with Bahdanau attention\n",
        "  '''\n",
        "  def __init__(self, input_vocab: int, embedding_dim: int, lstm_hidden_units: int):\n",
        "    '''\n",
        "      :param input_vocab - vocabluary dimension of the source language\n",
        "      :param embedding_dim - dimension of the source language words embeddings\n",
        "      :param lstm_hidden_units - the number of the LSTM cell units\n",
        "    '''\n",
        "    super(Encoder, self).__init__()\n",
        "    self.lstm_hidden_units = lstm_hidden_units\n",
        "    self.emedding = Embedding(input_dim=input_vocab,\n",
        "                              output_dim=embedding_dim,\n",
        "                              mask_zero=True,\n",
        "                              name='encoder_embedding')\n",
        "    self.lstm = LSTM(units=lstm_hidden_units,\n",
        "                     return_sequences=True,\n",
        "                     return_state=True,\n",
        "                     name='encoder_lstm')\n",
        "\n",
        "  def __call__(self, x, is_verbose=False):\n",
        "    '''\n",
        "      Calculate forward propagation through the Encoder\n",
        "      :param x - input sequence (batch_size, sequence_length)\n",
        "    '''\n",
        "    # Get embeddings.\n",
        "    # 'x' dimension is (batch_size, sequence_length)\n",
        "    # 'out' dimension is (batch_size, sequence_length, embedding_dim)\n",
        "    out = self.emedding(x)\n",
        "\n",
        "    # Hence we don't need LSTM output, we get only LSTM states (hidden state and cell state)\n",
        "    # One of the problems here is that dispite the return_sequences parameter is True,\n",
        "    # we get only last (after propagation a whole sequence) values of the states and\n",
        "    # didn't get the states after each timestep. We will struggle with this later.\n",
        "    output, h, c = self.lstm(out)\n",
        "\n",
        "    if is_verbose:\n",
        "      print(f\"Input shape {x.shape}. Shape after embedding: {out.shape}.\")\n",
        "      print(f\"Output LSTM shape: {output.shape}. Hidden state: {h.shape}. Cell state: {c.shape}\")\n",
        "\n",
        "    return h, c"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Encoder\n",
        "enc = Encoder(input_vocab=100, embedding_dim=64, lstm_hidden_units=16)\n",
        "input = np.zeros((4, 3))\n",
        "h, c = enc(input, is_verbose=True)\n",
        "\n",
        "assert input.shape == (4, 3), \"Wrong input shape\"\n",
        "assert h.shape == (4, 16), \"Wrong hidden state shape\"\n",
        "assert c.shape == (4, 16), \"Wrong cell state shape\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF5VnU--RRew",
        "outputId": "8587ce31-6f5e-4fbf-9175-59596e47e351"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape (4, 3). Shape after embedding: (4, 3, 64).\n",
            "Output LSTM shape: (4, 3, 16). Hidden state: (4, 16). Cell state: (4, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "B4DhtzjnPE_5"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  '''\n",
        "    Layers implements a Bahdanau attention mechanism\n",
        "  '''\n",
        "  def __init__(self, units: int, name=None):\n",
        "    '''\n",
        "      :param units - the number of the encoder and decoder hidden units.\n",
        "      This value can be obtained from the inputs dimensions but for the purpose of simplicity we will set it here.\n",
        "      :param name - tne name of the layer\n",
        "    '''\n",
        "    super(BahdanauAttention, self).__init__(name=name)\n",
        "    self.units = units\n",
        "    self.fc_encoder_states = Dense(units=units, activation='linear')\n",
        "    self.fc_decoder_states = Dense(units=units, activation='linear')\n",
        "    self.fc_combined = Dense(units=1, activation='linear')\n",
        "\n",
        "  def __call__(self, encoder_states, decoder_hidden_state, is_verbose=False):\n",
        "    '''\n",
        "      Calculate forward propagation through the Layer\n",
        "      :param encoder_states - encoder hidden states (batch_size, sequence_length, encoder_lstm_hidden_units)\n",
        "      :param decoder_hidden_state - decoder hidden state (batch_size, decoder_lstm_hidden_units)\n",
        "    '''\n",
        "\n",
        "    # Linear layer for the encoder hidden states (it has its own trainable weights).\n",
        "    fc_encoder_out = self.fc_encoder_states(encoder_states) # fc_encoder_out dimension is (batch_size, sequence_length, encoder_lstm_hidden_units)\n",
        "\n",
        "    # Linear layer for the decoder hidden state from the previous timestep (it has its own trainable weights).\n",
        "    fc_decoder_out = self.fc_decoder_states(decoder_hidden_state) # fc_decoder_out dimension is (batch_size, decoder_lstm_hidden_units)\n",
        "\n",
        "    # Add additional dimension to the fc_decoder_out\n",
        "    fc_decoder_out = tf.expand_dims(fc_decoder_out, axis=1) # fc_decoder_out dimension is (batch_size, 1, decoder_lstm_hidden_units)\n",
        "\n",
        "    # Calculate alignment score using linear layer  (it has its own trainable weights).\n",
        "    # Alignment_scores dimension is (batch_size, sequence_length, 1)\n",
        "    alignment_scores = self.fc_combined(tf.math.tanh(fc_encoder_out + fc_decoder_out))\n",
        "\n",
        "    # Remove a redundant dimension: (batch_size, sequence_length, 1) -> (batch_size, sequence_length)\n",
        "    # alignment_scores = np.squeeze(alignment_scores)\n",
        "\n",
        "    # Calculate attention weights of the each encoder hidden state within a batch\n",
        "    # softmax_alignment_scores dimension is (batch_size, sequence_length)\n",
        "    softmax_alignment_scores = tf.nn.softmax(alignment_scores, axis=1)\n",
        "\n",
        "    # Calculate context vector. Its dimension is (batch_size, encoder_lstm_hidden_units)\n",
        "    context_vector = tf.reduce_sum(softmax_alignment_scores * encoder_states, axis=1)\n",
        "\n",
        "    if is_verbose:\n",
        "      print(f\"Input: encoder_states shape: {encoder_states.shape}, decoder_hidden_state shape: {decoder_hidden_state.shape}\")\n",
        "      print(f\"fc_encoder_out shape: {fc_encoder_out.shape}, fc_decoder_out shape: {fc_decoder_out.shape}\")\n",
        "      print(f\"alignment_scores shape: {alignment_scores.shape}, softmax_alignment_scores shape: {softmax_alignment_scores.shape}\")\n",
        "      print(f\"context_vector shape: {context_vector.shape}\")\n",
        "\n",
        "    return context_vector, softmax_alignment_scores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test BahdanauAttention Layer\n",
        "ba = BahdanauAttention(units=64)\n",
        "encoder_states = np.zeros((4, 3, 16))\n",
        "decoder_hidden_state = np.zeros((4, 16))\n",
        "context_vector, softmax_alignment_scores = ba(encoder_states, decoder_hidden_state, is_verbose=True)\n",
        "\n",
        "assert encoder_states.shape == (4, 3, 16), \"Wrong encoder hidden states shape\"\n",
        "assert decoder_hidden_state.shape == (4, 16), \"Wrong decoder hidden state shape\"\n",
        "assert softmax_alignment_scores.shape == (4, 3, 1), \"Wrong attention weights shape\"\n",
        "assert context_vector.shape == (4, 16), \"Wrong context vector shape\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb3N28pVVQV2",
        "outputId": "1ea7fd69-1845-4054-dce9-6689b13f18e1"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: encoder_states shape: (4, 3, 16), decoder_hidden_state shape: (4, 16)\n",
            "fc_encoder_out shape: (4, 3, 64), fc_decoder_out shape: (4, 1, 64)\n",
            "alignment_scores shape: (4, 3, 1), softmax_alignment_scores shape: (4, 3, 1)\n",
            "context_vector shape: (4, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "tL1KwedDnTc3"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  '''\n",
        "    Decoder with Bahdanau attention mechanism\n",
        "  '''\n",
        "  def __init__(self, output_vocab, embedding_dim, lstm_hidden_units):\n",
        "    '''\n",
        "      :param output_vocab - vocabluary dimension of the target language\n",
        "      :param embedding_dim - dimension of the target language words embeddings\n",
        "      :param lstm_hidden_units - the number of the LSTM cell units\n",
        "    '''\n",
        "    super(Decoder, self).__init__()\n",
        "    self.emedding = Embedding(input_dim=output_vocab,\n",
        "                              output_dim=embedding_dim,\n",
        "                              mask_zero=True,\n",
        "                              name='decoder_embedding')\n",
        "\n",
        "    self.lstm = LSTM(units=lstm_hidden_units,\n",
        "                     return_sequences=True,\n",
        "                     return_state=True,\n",
        "                     name='decoder_lstm')\n",
        "\n",
        "    self.attention = BahdanauAttention(units=lstm_hidden_units,\n",
        "                                       name='decoder_attention')\n",
        "\n",
        "    # Dense layer with softmax activation function\n",
        "    self.output_dense = Dense(units=output_vocab,\n",
        "                              activation='softmax',\n",
        "                              name='decoder_output')\n",
        "\n",
        "  def __call__(self, x, decoder_states, encoder_states, is_verbose=False):\n",
        "    '''\n",
        "      Calculate forward propagation through the Decoder\n",
        "      :param x - input sequence (batch_size, sequence_length_of_target_lang)\n",
        "      :param decoder_states - hidden and cell decoder states from the previous timestep (or last encoder states for the first timestep)\n",
        "      Dimension ((batch_size, lstm_hidden_units), (batch_size, lstm_hidden_units))\n",
        "      :param encoder_states - hidden encoder states from the each timesteps  (batch_size, sequence_length, lstm_hidden_units)\n",
        "    '''\n",
        "    # Unpack decoder states\n",
        "    hidden_state, cell_state = decoder_states\n",
        "\n",
        "    # Calculate contect vector based on Bahdanau attention mechanism\n",
        "    # context_vector dimension is (batch_size, lstm_hidden_units)\n",
        "    context_vector, _ = self.attention(encoder_states, hidden_state)\n",
        "\n",
        "    # Get target language embedding\n",
        "    x_embd = self.emedding(x)\n",
        "\n",
        "    # Concatenate context_vector with the next embedded token\n",
        "    input = tf.concat([tf.expand_dims(context_vector, 1), x_embd], axis=-1)\n",
        "\n",
        "    # Get LSTM outputs\n",
        "    out_lstm, h, c = self.lstm(input, initial_state=decoder_states)\n",
        "\n",
        "    # Propagate LSTM output through dense layer with softmax activation function\n",
        "    out = self.output_dense(out_lstm)\n",
        "\n",
        "    if is_verbose:\n",
        "      print(f\"Input: encoder_states shape: {encoder_states.shape}, input hidden state: {hidden_state.shape}, input cell state: {cell_state.shape}\")\n",
        "      print(f\"context_vector shape: {context_vector.shape}, After embedding shape: {x_embd.shape}\")\n",
        "      print(f\"LSTM input shape: {input.shape}, LSTM output shape: {out_lstm.shape}\")\n",
        "      print(f\"LSTM output hidden state: {h.shape}, LSTM output cell state: {c.shape}\")\n",
        "      print(f\"Output after softmax: {out.shape}\")\n",
        "\n",
        "    return out, h, c"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Decoder\n",
        "dec = Decoder(output_vocab=100, embedding_dim=32, lstm_hidden_units=16)\n",
        "x = np.zeros((4, 1))\n",
        "decoder_states = tf.convert_to_tensor(np.zeros((4, 16)), dtype=tf.float32), tf.convert_to_tensor((np.zeros((4, 16))), dtype=tf.float32)\n",
        "encoder_states = tf.convert_to_tensor(np.zeros((4, 3, 16)), dtype=tf.float32)\n",
        "out, h, c = dec(x=x, decoder_states=decoder_states, encoder_states=encoder_states, is_verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7t2waVsfhYh",
        "outputId": "dfb3c49b-8fba-4205-80ac-f8510723e638"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: encoder_states shape: (4, 3, 16), input hidden state: (4, 16), input cell state: (4, 16)\n",
            "context_vector shape: (4, 16), After embedding shape: (4, 1, 32)\n",
            "LSTM input shape: (4, 1, 48), LSTM output shape: (4, 1, 16)\n",
            "LSTM output hidden state: (4, 16), LSTM output cell state: (4, 16)\n",
            "Output after softmax: (4, 1, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "id": "caH2BctcgtQ_"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqBahdanauAttention(tf.keras.Model):\n",
        "  '''\n",
        "  Encoder-Decoder network implements the Bahdanau attention mechanism\n",
        "  '''\n",
        "  def __init__(self,\n",
        "               input_vocab,\n",
        "               output_vocab,\n",
        "               encoder_embd_dim,\n",
        "               decoder_embd_dim,\n",
        "               encoder_lstm_units,\n",
        "               decoder_lstm_units,\n",
        "               max_output_length,\n",
        "               start_token_index,\n",
        "               end_token_index):\n",
        "    '''\n",
        "      :param input_vocab - vocabluary dimension of the source language\n",
        "      :param output_vocab - vocabluary dimension of the target language\n",
        "      :param encoder_embd_dim - dimension of the source language words embeddings\n",
        "      :param decoder_embd_dim - dimension of the target language words embeddings\n",
        "      :param encoder_lstm_units - the number of the LSTM cell units\n",
        "      :param decoder_lstm_units - the number of the LSTM cell units\n",
        "      :param max_output_length - the maximum length of the output sequence\n",
        "      :param start_token_index - index of the start token in the output vocabulary\n",
        "      :param end_token_index - index of the end token in the output vocabulary\n",
        "\n",
        "    '''\n",
        "    super(Seq2SeqBahdanauAttention, self).__init__()\n",
        "    self.encoder = Encoder(input_vocab=input_vocab,\n",
        "                           embedding_dim=encoder_embd_dim,\n",
        "                           lstm_hidden_units=encoder_lstm_units)\n",
        "    self.decoder = Decoder(output_vocab=output_vocab,\n",
        "                           embedding_dim=decoder_embd_dim,\n",
        "                           lstm_hidden_units=decoder_lstm_units)\n",
        "    self.max_output_length = max_output_length\n",
        "    self.start_token_index = start_token_index\n",
        "    self.end_token_index = end_token_index\n",
        "    self.__loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction='none')\n",
        "    self.__metric_object = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "\n",
        "  def __loss_function(self, true, pred):\n",
        "    '''\n",
        "    '''\n",
        "    loss = self.__loss_object(true, pred)\n",
        "    mask = tf.math.not_equal(true, 0)\n",
        "    mask = tf.cast(mask, dtype=loss.dtype)\n",
        "    return tf.reduce_mean(loss*mask)\n",
        "\n",
        "    # mask = tf.math.logical_not(tf.math.equal(true, 0))\n",
        "    # loss_ = self.__loss_object(true, pred)\n",
        "    # mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    # loss_ *= mask\n",
        "    # return tf.reduce_mean(loss_)\n",
        "\n",
        "  def __metric_function(self, true, pred):\n",
        "    '''\n",
        "    '''\n",
        "    mask = tf.math.not_equal(true, 0)\n",
        "    self.__metric_object.update_state(true[mask], pred[mask])\n",
        "    return self.__metric_object.result().numpy()\n",
        "\n",
        "  def __forward(self, X_encoder, X_decoder=None, Y_decoder=None):\n",
        "    '''\n",
        "      Forward propagation\n",
        "      :param X_encoder - input encoder sequence (source language) (batch_size, sequence_length_in_the_source_lang)\n",
        "      :param X_decoder - input decoder sequence (target language) (batch_size, sequence_length_in_the_target_lang + 2)\n",
        "      (ex. [start_token_index, word1_index, woprd2_index, end_token_index)\n",
        "      :param Y_decoder - output decoder sequence (target language) (batch_size, sequence_length_in_the_target_lang + 1)\n",
        "      (ex. [word1_index, woprd2_index, end_token_index)\n",
        "\n",
        "      We use X_decoder=None and Y_decoder=None for the purpose of prediction\n",
        "      We use X_decoder=None and Y_decoder is not None for the purpose of validation during training\n",
        "    '''\n",
        "    output = []\n",
        "    batch_size = X_encoder.shape[0]\n",
        "    encoder_states = []\n",
        "    loss = 0\n",
        "    accuracy = None\n",
        "\n",
        "    # Here we deal with the mentioned earlier problem of getting encoder hidden states on each timestep.\n",
        "    # As we mentoined before LSTM parameter 'return_sequences' doesn't affect on the hidden and cell states, i.e.\n",
        "    # we can't get LSTM states after every timestep. Therefore we need do it manually. It means the following:\n",
        "    # 1) we take the first token of the input sequence, propagate it through the encoder and save the LSTM states.\n",
        "    # 2) we take the two first tokens of the input sequence, propagate them through the encoder and save the last LSTM states.\n",
        "    # 3) We repeat step 2 adding the next token and save the last LSTM states.\n",
        "\n",
        "    for t in range(X_encoder.shape[1]):\n",
        "      h, c = self.encoder(X_encoder[:, :t+1])\n",
        "      encoder_states.append(h)\n",
        "    encoder_states = tf.stack(encoder_states, axis=1) # make tensor from the list\n",
        "\n",
        "    # save the last encoder hidden and cell states, since they are the initial decoder states\n",
        "    hidden_state = encoder_states[:, -1, :]\n",
        "    cell_state = c\n",
        "\n",
        "    if X_decoder is not None and Y_decoder is not None: # if we train network\n",
        "      # for every timestep (i.e. every token) of the target language sequence\n",
        "      for t in range(X_decoder.shape[1]):\n",
        "        # Set the decoder_input to the t-th token of the decoder input sequence.\n",
        "        # We use here the teacher forcing method for faster and efficient decoder training.\n",
        "        # The method uses the ground true as the decoder input instead of the prediction\n",
        "        # from the previous timestep. We need decoder_input to have the dimension (batch_size, 1)\n",
        "        decoder_input = X_decoder[:, t:t+1]\n",
        "        # print(decoder_input.shape)\n",
        "\n",
        "        # Calculate decoder output and states. We\n",
        "        out, hidden_state, cell_state = self.decoder(x=decoder_input,\n",
        "                                                     decoder_states=(hidden_state, cell_state),\n",
        "                                                     encoder_states=encoder_states)\n",
        "\n",
        "        output.append(out) # Collect output token\n",
        "        loss += self.__loss_function(Y_decoder[:, t], out) # Calculate loss function\n",
        "        accuracy = self.__metric_function(Y_decoder[:, t], np.squeeze(out)) # Calculate accuracy\n",
        "    else: # if we validate (calculate loss and accuracy on the test set) the network or make prediction\n",
        "        current_step = 0 # current timestep\n",
        "\n",
        "        # Set the first decoder input to the start token index. decoder_input dimension is (batch_size, )\n",
        "        decoder_input = np.full((batch_size, 1), self.start_token_index)\n",
        "\n",
        "        # Iterate till the maximum outpt length will be achieved.\n",
        "        while current_step<self.max_output_length:\n",
        "          out, hidden_state, cell_state = self.decoder(x=decoder_input,\n",
        "                                                       decoder_states=(hidden_state, cell_state),\n",
        "                                                       encoder_states=encoder_states)\n",
        "          if Y_decoder is not None: # if we validate the network\n",
        "            true, pred = Y_decoder[:, current_step], np.squeeze(out)\n",
        "            loss += self.__loss_function(true, pred) # loss function\n",
        "            accuracy = self.__metric_function(true, pred) # accuracy metric\n",
        "\n",
        "          # Get the indexes of the predicted tokens. Dimension is (batch_size, )\n",
        "          tokens = np.argmax(np.squeeze(out), axis=1)\n",
        "\n",
        "          # Here we don't use teacher forcing, i.e. the output from the previous timestep\n",
        "          # is the input for the current one.\n",
        "          decoder_input = tf.expand_dims(tokens, 1)\n",
        "          output.append(out)\n",
        "          current_step += 1\n",
        "\n",
        "    # If it's not a inference we calculate loss function value over batch\n",
        "    batch_loss = tf.reduce_sum(loss) / Y_decoder.shape[1] if Y_decoder is not None else None\n",
        "    return output, loss, batch_loss, accuracy\n",
        "\n",
        "  def __train_step(self, X_encoder, X_decoder, Y_decoder, learning_rate):\n",
        "    '''\n",
        "      Perform one train iteration\n",
        "\n",
        "      :param X_encoder - input encoder sequence (source language) (batch_size, sequence_length_in_the_source_lang)\n",
        "      :param X_decoder - input decoder sequence (target language) (batch_size, sequence_length_in_the_target_lang + 2)\n",
        "      (ex. [start_token_index, word1_index, woprd2_index, end_token_index)\n",
        "      :param Y_decoder - output decoder sequence (target language) (batch_size, sequence_length_in_the_target_lang + 1)\n",
        "      (ex. [word1_index, woprd2_index, end_token_index)\n",
        "      :param learning_rate - an optimizer learning rate\n",
        "    '''\n",
        "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "    with tf.GradientTape() as tape:\n",
        "      _, loss, batch_loss, accuracy = self.__forward(X_encoder, X_decoder, Y_decoder)\n",
        "      variables = self.encoder.trainable_variables + self.decoder.trainable_variables\n",
        "      gradients = tape.gradient(loss, variables)\n",
        "      optimizer.apply_gradients(zip(gradients, variables))\n",
        "    return batch_loss, accuracy\n",
        "\n",
        "  def __align_to_length(self, X, batch_size=32):\n",
        "    '''\n",
        "    Reorder dataset according the sample sequence lengths\n",
        "\n",
        "    It's known that the Bahdanau attention mechanism requires all encoder hidden states.\n",
        "    In general samples in the batch have different lengths, hence, they have different number of hidden states.\n",
        "    So, a new problem arises - how can we store a batch with the different row lengths (row is a vector of the encoder hidden states).\n",
        "    There are several ways to manage it. One of them can be transform the dataset so that each batch consists the\n",
        "    sequences with the same lengths.\n",
        "\n",
        "    :param X - dataset\n",
        "    :param batch_size - batch size\n",
        "\n",
        "    Ex.\n",
        "    An original dataset X\n",
        "    [\n",
        "      [1, 2, 3],\n",
        "      [4, 5, 6, 7],\n",
        "      [8, 9],\n",
        "      [10, 11, 12, 13],\n",
        "      [14, 15, 16],\n",
        "      [17, 18]\n",
        "    ]\n",
        "    batch_size = 2\n",
        "    A new dataset\n",
        "    [\n",
        "      [1, 2, 3],\n",
        "      [14, 15, 16],\n",
        "      [4, 5, 6, 7],\n",
        "      [10, 11, 12, 13],\n",
        "      [8, 9],\n",
        "      [17, 18]\n",
        "    ]\n",
        "    So, after splitting into batches, each batch will contain the sequences with the same lengths\n",
        "    '''\n",
        "    c = Counter([len(x[0]) for x in X])\n",
        "    X_new = []\n",
        "    for length, count in c.most_common():\n",
        "      if count >= batch_size:\n",
        "        batches_count = count//batch_size\n",
        "        X_new += list(filter(lambda x: len(x[0])==length, X))[:batches_count*batch_size]\n",
        "    return X_new\n",
        "\n",
        "  def __generate_batches(self, X, Y, batch_size=32):\n",
        "    '''\n",
        "     Batch generator.\n",
        "\n",
        "     Each batch is the number of tuple: (Encoder_input, Decoder_input, Decoder_output a.k.a. ground truth)  )\n",
        "     :param X - encoder and decoder inputs\n",
        "     :param Y - decoder output\n",
        "     :param batch_size - batch size\n",
        "    '''\n",
        "    X_encoder, X_decoder = zip(*X)\n",
        "    ds = list(zip(X_encoder, X_decoder, Y))\n",
        "    X_new = self.__align_to_length(ds, batch_size)\n",
        "    X_encoder, X_decoder, Y_decoder = zip(*X_new)\n",
        "    X_encoder, X_decoder, Y_decoder = list(X_encoder), list(X_decoder), list(Y_decoder)\n",
        "    batches_count = len(X_encoder) // batch_size\n",
        "    for i in range(batches_count):\n",
        "      lower_idx, upper_idx = i*batch_size, (i+1)*batch_size\n",
        "      yield np.array(X_encoder[lower_idx:upper_idx]), \\\n",
        "            np.array(X_decoder[lower_idx:upper_idx]), \\\n",
        "            np.array(Y_decoder[lower_idx:upper_idx])\n",
        "\n",
        "  def fit(self, X_encoder, X_decoder, Y_decoder, epoch=20, batch_size=32, train_size=0.8, learning_rate=0.001):\n",
        "    '''\n",
        "      Train network\n",
        "\n",
        "      :param X_encoder - input encoder sequence (source language) (batch_size, sequence_length_in_the_source_lang)\n",
        "      :param X_decoder - input decoder sequence (target language) (batch_size, sequence_length_in_the_target_lang + 2)\n",
        "      (ex. [start_token_index, word1_index, woprd2_index, end_token_index)\n",
        "      :param Y_decoder - output decoder sequence (target language) (batch_size, sequence_length_in_the_target_lang + 1)\n",
        "      :param epoch - the number of epochs\n",
        "      :param batch_size - batch size\n",
        "      :param train_size - train dataset size (0 <= train_size <= 1)\n",
        "      :param learning_rate - an optimizer learning rate\n",
        "    '''\n",
        "\n",
        "    # Split input and outputs into train and test. We need to combine two inputs (encoder and decoder)\n",
        "    X_train, X_test, Y_decoder_train, Y_decoder_test = train_test_split(list(zip(X_encoder, X_decoder)),\n",
        "                                                                        Y_decoder,\n",
        "                                                                        train_size=train_size)\n",
        "    # Align the train and test datasets according to the batch_size and sequences lengths\n",
        "    X_new_train = self.__align_to_length(X_train, batch_size)\n",
        "    X_new_test = self.__align_to_length(X_test, batch_size)\n",
        "\n",
        "    # Calculate some usefull values\n",
        "    total_train_batches = len(X_new_train) // batch_size\n",
        "    total_test_batches = len(X_new_test) // batch_size\n",
        "    train_ds_size = len(X_new_train)\n",
        "    test_ds_size = len(X_new_test)\n",
        "\n",
        "    # dictionary for saving the loss function and accuracy values\n",
        "    history = {\"train_loss\": [], \"train_accuracy\": [], \"test_loss\": [], \"test_accuracy\": []}\n",
        "\n",
        "    print(f\"Train dataset: {total_train_batches} batches, {train_ds_size} samples\")\n",
        "    print(f\"Test dataset: {total_test_batches} batches, {test_ds_size} samples\")\n",
        "    print(f\"{'='*10}\")\n",
        "\n",
        "    # Iterate over epochs\n",
        "    for ep in range(1, epoch+1):\n",
        "      print(f\"Epoch {ep}/{epoch}\")\n",
        "\n",
        "      # Train phase\n",
        "      total_loss = 0\n",
        "      self.__metric_object.reset_state()\n",
        "      # Iterate over batches\n",
        "      for batch, (X_batch_encoder,\n",
        "                  X_batch_decoder,\n",
        "                  Y_batch_decoder) in tqdm(enumerate(self.__generate_batches(X_train,\n",
        "                                                                             Y_decoder_train,\n",
        "                                                                             batch_size=batch_size)),\n",
        "                                           desc=f\"Train dataset\"):\n",
        "        # Propagate the batch through network and modify weights\n",
        "        batch_loss, batch_accuracy = self.__train_step(X_batch_encoder, X_batch_decoder, Y_batch_decoder, learning_rate)\n",
        "\n",
        "        total_loss += batch_loss\n",
        "        accuracy = batch_accuracy\n",
        "\n",
        "      total_loss /= total_train_batches\n",
        "      history[\"train_loss\"].append(total_loss.numpy())\n",
        "      history[\"train_accuracy\"].append(np.mean(accuracy))\n",
        "      print(f\"Loss on train: {total_loss.numpy():.4f} Accuracy on train: {accuracy:.4f}\")\n",
        "\n",
        "      # Test phase\n",
        "      total_loss = 0\n",
        "      self.__metric_object.reset_state()\n",
        "\n",
        "      # Iterate over batches. We don't need decoder input here because we won't use teacher forcing\n",
        "      for batch, (X_batch_encoder,\n",
        "                  _,\n",
        "                  Y_batch_decoder) in tqdm(enumerate(self.__generate_batches(X_test,\n",
        "                                                                             Y_decoder_test,\n",
        "                                                                             batch_size=batch_size)),\n",
        "                                           desc=f\"Test dataset\"):\n",
        "        _, _, batch_loss, batch_accuracy = self.__forward(X_batch_encoder,\n",
        "                                                          None,\n",
        "                                                          Y_batch_decoder)\n",
        "        total_loss += batch_loss\n",
        "        accuracy = batch_accuracy\n",
        "\n",
        "      total_loss /= total_test_batches\n",
        "      history[\"test_loss\"].append(total_loss.numpy())\n",
        "      history[\"test_accuracy\"].append(np.mean(accuracy))\n",
        "      print(f\"Loss on test: {total_loss.numpy():.4f} Accuracy on test: {accuracy:.4f}\")\n",
        "    return history\n",
        "\n",
        "  def predict(self, X_encoder):\n",
        "    '''\n",
        "    Make prediction\n",
        "\n",
        "    :param X_encoder - input encoder sequence (source language) (batch_size, sequence_length_in_the_source_lang)\n",
        "    '''\n",
        "    out, _, _, _ = self.__forward(X_encoder)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "id": "R7HQ2-Sqlpye"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 32\n",
        "lstm_hidden_units = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "id": "Jn12K0-qgtY0"
      },
      "outputs": [],
      "source": [
        "model = Seq2SeqBahdanauAttention(input_vocab=input_vocab,\n",
        "                                 output_vocab=output_vocab,\n",
        "                                 encoder_embd_dim=embedding_dim,\n",
        "                                 decoder_embd_dim=embedding_dim,\n",
        "                                 encoder_lstm_units=lstm_hidden_units,\n",
        "                                 decoder_lstm_units=lstm_hidden_units,\n",
        "                                 max_output_length=decoder_vec.max_length,\n",
        "                                 start_token_index=decoder_vec.vocabulary.index(START_TOKEN),\n",
        "                                 end_token_index=decoder_vec.vocabulary.index(END_TOKEN))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCJ4QCjxGVnB",
        "outputId": "dcbf88ea-c4b3-4d2f-ddaf-ca47d2a07b1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset: 247 batches, 7904 samples\n",
            "Test dataset: 61 batches, 1952 samples\n",
            "==========\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:18,  1.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 3.7544 Accuracy on train: 0.2371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 4.1925 Accuracy on test: 0.0960\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:19,  1.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 3.2196 Accuracy on train: 0.3065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 4.2576 Accuracy on test: 0.1388\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:17,  1.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 3.0282 Accuracy on train: 0.3487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:19,  3.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 4.0639 Accuracy on test: 0.2168\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:21,  1.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 2.8918 Accuracy on train: 0.3783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 4.0656 Accuracy on test: 0.2227\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:16,  1.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 2.7838 Accuracy on train: 0.4056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 4.0685 Accuracy on test: 0.2214\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:15,  1.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 2.6902 Accuracy on train: 0.4260\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.9173 Accuracy on test: 0.2301\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:16,  1.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 2.6104 Accuracy on train: 0.4451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.8012 Accuracy on test: 0.2525\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:15,  1.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 2.5334 Accuracy on train: 0.4634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.7328 Accuracy on test: 0.2672\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:17,  1.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 2.4701 Accuracy on train: 0.4788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.7206 Accuracy on test: 0.2743\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:16,  1.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 2.4138 Accuracy on train: 0.4903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.7042 Accuracy on test: 0.2878\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:12,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 2.3626 Accuracy on train: 0.5010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.6610 Accuracy on test: 0.2944\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:16,  1.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 2.3157 Accuracy on train: 0.5108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:17,  3.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.6260 Accuracy on test: 0.3033\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:12,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 2.2723 Accuracy on train: 0.5188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.6100 Accuracy on test: 0.3058\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:15,  1.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 2.2347 Accuracy on train: 0.5269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.6437 Accuracy on test: 0.2972\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:14,  1.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 2.1998 Accuracy on train: 0.5338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.6326 Accuracy on test: 0.3045\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:17,  1.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 2.1659 Accuracy on train: 0.5404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.6215 Accuracy on test: 0.3120\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:13,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 2.1347 Accuracy on train: 0.5457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.6351 Accuracy on test: 0.3119\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:16,  1.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 2.1042 Accuracy on train: 0.5518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.6387 Accuracy on test: 0.3188\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:16,  1.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 2.0736 Accuracy on train: 0.5584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.5935 Accuracy on test: 0.3291\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:15,  1.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 2.0444 Accuracy on train: 0.5633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.5878 Accuracy on test: 0.3304\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:17,  1.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 2.0177 Accuracy on train: 0.5697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.5716 Accuracy on test: 0.3397\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:17,  1.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 1.9904 Accuracy on train: 0.5744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.5683 Accuracy on test: 0.3454\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:16,  1.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 1.9666 Accuracy on train: 0.5787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.6328 Accuracy on test: 0.3406\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:16,  1.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 1.9433 Accuracy on train: 0.5827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.6078 Accuracy on test: 0.3423\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:16,  1.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 1.9198 Accuracy on train: 0.5875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.6041 Accuracy on test: 0.3458\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:14,  1.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 1.8975 Accuracy on train: 0.5916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.5858 Accuracy on test: 0.3482\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:16,  1.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 1.8770 Accuracy on train: 0.5943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.6376 Accuracy on test: 0.3471\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:17,  1.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 1.8567 Accuracy on train: 0.5982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.6639 Accuracy on test: 0.3431\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:20,  1.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 1.8403 Accuracy on train: 0.6020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:19,  3.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.6457 Accuracy on test: 0.3507\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train dataset: 247it [02:17,  1.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on train: 1.8226 Accuracy on train: 0.6058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test dataset: 61it [00:18,  3.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on test: 3.6903 Accuracy on test: 0.3487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_encoder, X_decoder, Y_decoder, epoch=30, batch_size=32, train_size=0.8, learning_rate=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(base_path + 'Data/machine_translation_bahdanau_attention_history.pickle', 'wb') as f:\n",
        "#     pickle.dump(history, f)"
      ],
      "metadata": {
        "id": "e1mQ2TQbWItn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(base_path + 'Data/machine_translation_bahdanau_attention_history.pickle', 'rb') as f:\n",
        "#     history = pickle.load(f)"
      ],
      "metadata": {
        "id": "W_TqkLyyDfgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data=history)\n",
        "# Plot the learning curves (the loss function and the accuracy metric)\n",
        "# which calculated on the training and test datasets\n",
        "_, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "sns.lineplot(data=df[['train_loss', 'test_loss']], ax=axs[0])\n",
        "sns.lineplot(data=df[['train_accuracy', 'test_accuracy']], ax=axs[1])\n",
        "axs[0].set_title('Loss function')\n",
        "axs[1].set_title('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "BLfI5X5UF8rX",
        "outputId": "efdc2e9c-4122-43cf-8a04-3e4b36767e81"
      },
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def metric_function(true, pred):\n",
        "  '''\n",
        "  '''\n",
        "  mask = tf.math.logical_not(tf.math.equal(true, 0))\n",
        "  metric_ = tf.keras.metrics.SparseCategoricalAccuracy()(true, pred)\n",
        "  mask = tf.cast(mask, dtype=metric_.dtype)\n",
        "  metric_ *= mask\n",
        "  return metric_\n",
        "\n",
        "pred1 = tf.convert_to_tensor(np.array([[0.3, 0.5, 0.1], [0.3, 0.1, 0.1], [0.3, 0.5, 0.1], [0.3, 0.5, 0.8]]))\n",
        "true1 = tf.convert_to_tensor(np.array([1, 2, 0, 0]))\n",
        "\n",
        "pred2= tf.convert_to_tensor(np.array([[0.3, 0.5, 0.9], [0.3, 0.7, 0.1], [0.3, 0.5, 0.1], [0.3, 0.5, 0.8]]))\n",
        "true2 = tf.convert_to_tensor(np.array([2, 1, 0, 0]))\n",
        "\n",
        "metric_function(true2, pred2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7X5ZeiOBdJD",
        "outputId": "93e16925-f80a-4092-8e37-5c477e44e526"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.5, 0.5, 0. , 0. ], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.math.not_equal(true1, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCWZtRegRbTf",
        "outputId": "fac433c4-3d18-44b8-fd8b-e9961d365e71"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True,  True, False, False])>"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred1[true1 != 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qxt1m0TBSKxm",
        "outputId": "d5413cd2-3aa4-4985-b6e4-56551fb63431"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float64, numpy=\n",
              "array([[0.3, 0.5, 0.1],\n",
              "       [0.3, 0.1, 0.1]])>"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = tf.keras.metrics.SparseCategoricalAccuracy()"
      ],
      "metadata": {
        "id": "45IrAsSpCVnn"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = tf.math.not_equal(true1, 0)"
      ],
      "metadata": {
        "id": "B5u8vNX3TDPW"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = [1, 2]\n",
        "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
        "loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
        "loss.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMdtL50sbUhf",
        "outputId": "5e783923-c007-435d-ae5e-6c956b3b80bb"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.05129344, 2.3025851 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvQ0sxwM1BA2",
        "outputId": "0e1f34a2-571e-4f5c-9024-60f4baf28840"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=bool, numpy=array([False, False])>"
            ]
          },
          "metadata": {},
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = tf.keras.losses.SparseCategoricalCrossentropy(reduction='none')\n",
        "loss = l(y_true, y_pred)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e62sP2GbXcL",
        "outputId": "11258615-7420-411d-844d-85c1a649c350"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.05129344, 2.3025851 ], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = tf.math.equal(y_true, 0)\n",
        "mask = tf.cast(mask, dtype=loss.dtype)\n",
        "loss*mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rORXnwaJzNSW",
        "outputId": "bf732608-ef70-44a1-aade-a3836baad9b9"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 239
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2V2Z8jmfIbnz/Tl4/plSu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}